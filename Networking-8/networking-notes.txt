cat /proc/sys/net/ipv4/ip_forward is default 0
echo 1 > /proc/sys/net/ipv4/ip_forward and ping
or
/etc/sysctl.conf

ip link
ip addr
ip addr add 192.168.1.10/24 dev eth0
ip route or route
ip route add 192.168.1.0/24 via 192.168.2.1 	//route

DNS
cat /etc/hosts

DNS server - 192.168.1.100

host A -> cat /etc/resolv.conf and change nameserver 192.168.1.100

======================================================================

network namespace
-> ip netns add red		//network namespace in linux
-> ip netns add blue		//newwork namespace in linux
-> ip netns exec red iplink
  or 
   ip -n red link

there are two machine in this node blue and red.
ip link add veth-red type veth peer name veth-blue
ip link set veth-red netns red
ip link set veth-blue netns blue
ip -n red addr add 192.168.15.1 dev veth-red
ip -n blue addr add 192.168.15.2 dev veth-blue

ip -n red link set veth-red up
ip -n blue link set veth-blue up
ip netns exec red ping 192.168.15.2
ip netns exec red arp
ip netns exec blue arp

arp 	//type in the node we cant see machine arp

create virtual switch (central namespace)
ip link add v-net-0 type bridge
ip link			//we see the namespace
ip link set dev v-net-0 up

first we must delete red and blue link
-> ip -n red link del veth-red 			//the other is delete automatically

create cable
ip link add veth-red type veth peer name veth-red-br
ip link add veth-blue type veth peer name veth-blue-br

connect with vswitch
ip link set veth-red netns red
ip link ste veth-red-br master v-net-0
ip link set veth-blue netns blue
ip link set veth-blue-br master v-net-0

giving ip and up
ip -n red addr add 192.168.15.1 dev veth-red
ip -n blue addr add 192.168.15.2 dev veth-blue
ip -n red link set veth-red up
ip -n blue link set veth-blue up

my-host
ping 192.168.15.1 	//not reach to vnet
ip addr add 192.168.15.5/24 dev v-net-0		//to connect

when we went to ping 192.168.1.0(other network) from blue, we must add route
ip net exec blue ip route add 192.168.1.0/24 via 192.168.15.5
ip netns exec blue ping 192.168.1.3			//cant ping because it is home network and cant go outside with rules
iptables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE

when we want to go the public 8/8/8/8, we must use 
ip netns exec blue ping 8.8.8.8
ip netns exec blue route
ip netns exec blue ip route add default via 192.168.15.5
ip netns exec blue ping 8.8.8.8

=========================================================================

network in docker 
-> docker run --network none nginx		//none network
-> docker run --network host nginx 		//host network http://192.168.1.1:80
-> docker run nginx				//bridge network, default private network is 172.16.0.0

-> docker network ls
-> ip netns	
-> ip link

-> iptables -nvL -t nat

=======================================================================================

CNI (container networking interface)

network namespaces
1. create network namespace
2. create bridge network/interface
3. create vEth pairs (pipe, virtual cable)
4. attach vEth to Namespace
5. Attach other vEth to Brdige
6. Assign IP address
7. Bring the interfaces up
8. Enable NAT - Ip masquerade

cluster networking 
-> master kubeapi server - 6443
-> master and worker kubelet - 10250
-> master kubescheduler - 10251
-> master kube-controller manager - 10252
-> master etcd server - 2379
-> woker services port is 30000 - 32767

commands
-> ip link
-> ip addr
-> ip addr add 192.168.1.10/24 dev eth0
-> ip route
-> ip route add 192.168.1.0/24 via 192.168.2.1
-> cat /proc/sys/net/ipv4/ip_forward
-> arp
-> netstat -antp
-> route

What is the network interface configured for cluster connectivity on the master node?
node-to-node communication
Ans: ip link, ens3

What is the MAC address of the interface on the master node?
Ans: ip link show ens3

We use Docker as our container runtime. What is the interface/bridge created by Docker on this host?
Ans: Run the command ip link and look for a bridge interface created by docker

If you were to ping google from the master node, which route does it take?
What is the IP address of the Default Gateway?
Ans: ip route show default

=============================================================


pod networking 
-every pod should have an IP address
-every pod should be able to communicate with every other pod in the same node.
-every pod should be able to communicate with every other pod on other nodes without NAT.

example create node1, node2, node3
-ip link add v-net-0 type bridge
-ip link set dev v-net-0 up
-ip addr add 10.244.1.1/24 dev v-net-0		//node1,2,3 their own
-ip route add 10.244.2.2 via 192.168.1.12
-ip route add 10.244.3.2 via 192.168.1.13
it is so complex and must be suitable for small network. not large network
so we must use CNI

kubelet 
|
--cni-conf-dir=/etc/cni/net.d
|
--cni-bin-dir=/etc/cni/bin
|
./net-script.sh add <container> <namespace>

========================================================

CNI in kubernetes

CNI
- container runtime must create network namespace
- identify network the container must attach to
- container runtime to invoke network plugin (bridge) when container is added
- container runtime to invoke network plugin (bridge) when container id deleted
- json format of the network configuration
viewing kubelet options
- ps -aux | grep kubelet
- ls /opt/cni/bin
- ls /etc/cni/net.d		//config directory
- cat /etc/cni/net.d/10-bridge.conf

CNI weave
deploy weave
-> kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
-> kubectl get pods -n kube-system
-> kubectl logs weave-net-5gcmb weave -n kube-system

install 
https://www.weave.works/docs/net/latest/kubernetes/kube-addon/

========================================================================

ipam weave (ip address management0

How many weave agents/peers are deployed in this cluster?
Ans: kubectl get pods -n kube-system

=========================================================================

service networking
-> kubelet get pods -o wide
-> kubelet get service
-> iptables -L -t net | grep db-service
-> cat /var/log/kube-proxy.log	
-> kubectl logs weave-net-fjd97 weave -n kube-system

What type of proxy is the kube-proxy configured to use?
Ans: kubectl logs kube-proxy-ft6n7 -n kube-system
=========================================================================

DNS in kubernets
when we have seprate namespace 
-default and apps
-web server is located in apps namespace with 10.107.37.188
-kubeDNS auto record the web-service=10.107.37.188
-curl http://web-service		//same namespace
-curl http://web-service.apps 		//sepreate namespace

fully domain name

hostname	namespace	types	Root		IPAddress
web-service	apps		svc	cluster.local	10.107.37.188
10-244-2-5	apps		pod	cluster.local	10.244.2.5

curl http://web-service.apps.svc.cluster.local

============================================================================

how to implement DNS
prior to version 1.12 		-> kube-dns
version1.12			-> coreDNS


location
cat /etc/coredns/Corefile
kubectl get configmap -n kube-system

What is the root domain/zone configured for this kubernetes cluster?
ans: kubectl describe configmap coredns -n kube-system

==============================================================================

ingress network

ingress network solution (ingress controller, not deploy by default)
1.deploy
1. nginx
2. HAproxy
3. traefik
4. contour
5. istio
6. GCP Https, Load Balancer (GCE)

2.configuration (ingress resources)

start -> create configmap, nginx controller, nodePort, Service Account(Auth) 

lab
ingress-wear.yml

ingres resources
www.my-online-store.com		//rule1
www.wear.my-online-store.com	//rule2
www.watch.my-online-store.com	//rule3
everything else			//rule4

You are requested to make the new application available at /pay.
Identify and implement the best approach to making this application available on the ingress controller and test to make sure its working. Look into annotations: rewrite-target as well.
Ans: 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: test-ingress
  namespace: critical-space
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - path: /pay
        backend:
          serviceName: pay-service
          servicePort: 8282
https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/rewrite


create -> namespace, configmap, service account, create role and rolebinding, ingress controller, service , resource




The NGINX Ingress Controller requires a ConfigMap object. Create a ConfigMap object in the ingress-space.
Use the given spec on the right. No data needs to be configured in the ConfigMap.
Ans: kubectl create configmap nginx-configuration --namespace ingress-space

The NGINX Ingress Controller requires a ServiceAccount. Create a ServiceAccount in the ingress-space.
Use the given spec on the right.
Ans: 'kubectl create serviceaccount ingress-serviceaccount --namespace ingress-spacee

Let us now deploy the Ingress Controller. Create a deployment using the file given.
The Deployment configuration is given at /root/ingress-controller.yaml. There are several issues with it. Try to fix them.
Ans: 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ingress-controller
  namespace: ingress-space
spec:
  replicas: 1
  selector:
    matchLabels:
      name: nginx-ingress
  template:
    metadata:
      labels:
        name: nginx-ingress
    spec:
      serviceAccountName: ingress-serviceaccount
      containers:
        - name: nginx-ingress-controller
          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.21.0
          args:
            - /nginx-ingress-controller
            - --configmap=$(POD_NAMESPACE)/nginx-configuration
            - --default-backend-service=app-space/default-http-backend
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: 80
            - name: https
              containerPort: 443

Let us now create a service to make Ingress available to external users.
Create a service following the given specs.
Name: ingress
Type: NodePort
Port: 80
TargetPort: 80
NodePort: 30080
Use the right selector
Ans: 
Answer file is located at /var/answers/ingress-service.yaml. Use the command kubectl expose deployment -n ingress-space ingress-controller --type=NodePort --port=80 --name=ingress --dry-run -o yaml >ingress.yaml

Create the ingress resource to make the applications available at /wear and /watch on the Ingress service.
Create the ingress in the app-space
Ingress Created
Path: /wear
Path: /watch
Configure correct backend service for /wear
Configure correct backend service for /watch
Configure correct backend port for /wear service
Configure correct backend port for /watch service
Ans:
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ingress-wear-watch
  namespace: app-space
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /wear
        backend:
          serviceName: wear-service
          servicePort: 8080
      - path: /watch
        backend:
          serviceName: video-service
          servicePort: 8080